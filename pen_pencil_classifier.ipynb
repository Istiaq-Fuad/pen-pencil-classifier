{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe866071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c931f236",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7e477c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path(\"processed_dataset\")\n",
    "\n",
    "classes = ['pen', 'pencil']\n",
    "for class_name in classes:\n",
    "    class_path = dataset_path / class_name\n",
    "    num_images = len(list(class_path.glob('*.jpg')))\n",
    "    print(f\"{class_name.capitalize()}: {num_images} images\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "fig.suptitle(\"Sample Images from Dataset\", fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, class_name in enumerate(classes):\n",
    "    class_path = dataset_path / class_name\n",
    "    image_files = list(class_path.glob('*.jpg'))[:5]\n",
    "    \n",
    "    for j, img_path in enumerate(image_files):\n",
    "        img = load_img(img_path, target_size=(224, 224))\n",
    "        axes[i, j].imshow(img)\n",
    "        axes[i, j].axis('off')\n",
    "        axes[i, j].set_title(f\"{class_name}\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0b0546",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ea7a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    str(dataset_path),\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    str(dataset_path),\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    str(dataset_path),\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=1,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"\\nClass indices: {train_generator.class_indices}\")\n",
    "print(f\"Training samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {validation_generator.samples}\")\n",
    "print(f\"Test samples: {test_generator.samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5353b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(\n",
    "    input_shape=(*IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "print(f\"Base model: MobileNetV2\")\n",
    "print(f\"Total layers in base model: {len(base_model.layers)}\")\n",
    "print(f\"Base model trainable: {base_model.trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01923f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "print(\"\\nModel Summary:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e5a52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint, early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324ba65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a856d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
    "axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy', marker='s')\n",
    "axes[0].set_title('Model Accuracy Over Epochs', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(history.history['loss'], label='Training Loss', marker='o')\n",
    "axes[1].plot(history.history['val_loss'], label='Validation Loss', marker='s')\n",
    "axes[1].set_title('Model Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(history.history['auc'], label='Training AUC', marker='o')\n",
    "axes[2].plot(history.history['val_auc'], label='Validation AUC', marker='s')\n",
    "axes[2].set_title('Model AUC Over Epochs', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('AUC')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee427f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy, test_auc = model.evaluate(test_generator, verbose=1)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Test Results:\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"Test AUC: {test_auc:.4f}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944b9039",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "\n",
    "y_pred_proba = model.predict(test_generator, verbose=1)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "y_true = test_generator.classes\n",
    "\n",
    "class_names = list(test_generator.class_indices.keys())\n",
    "print(f\"\\nClass names: {class_names}\")\n",
    "print(f\"Total predictions: {len(y_pred)}\")\n",
    "print(f\"Predictions shape: {y_pred.shape}\")\n",
    "print(f\"True labels shape: {y_true.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1e493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            cbar_kws={'label': 'Count'},\n",
    "            annot_kws={'size': 16})\n",
    "plt.title('Confusion Matrix', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nConfusion Matrix Breakdown:\")\n",
    "print(f\"True Negatives (Pen predicted as Pen): {cm[0][0]}\")\n",
    "print(f\"False Positives (Pen predicted as Pencil): {cm[0][1]}\")\n",
    "print(f\"False Negatives (Pencil predicted as Pen): {cm[1][0]}\")\n",
    "print(f\"True Positives (Pencil predicted as Pencil): {cm[1][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c80ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_true, y_pred, target_names=class_names, digits=4)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(report)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(y_true, y_pred, average='binary')\n",
    "recall = recall_score(y_true, y_pred, average='binary')\n",
    "f1 = f1_score(y_true, y_pred, average='binary')\n",
    "\n",
    "metrics = ['Precision', 'Recall', 'F1-Score', 'Accuracy']\n",
    "values = [precision, recall, f1, test_accuracy]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(metrics, values, color=['#3498db', '#2ecc71', '#f39c12', '#e74c3c'], alpha=0.8, edgecolor='black')\n",
    "plt.ylim(0, 1.1)\n",
    "plt.ylabel('Score', fontsize=12)\n",
    "plt.title('Model Performance Metrics', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar, value in zip(bars, values):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "             f'{value:.4f}', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038ef48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 16\n",
    "indices = np.random.choice(len(test_generator.filenames), num_samples, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "fig.suptitle('Sample Predictions with Confidence Scores', fontsize=18, fontweight='bold', y=0.995)\n",
    "\n",
    "for idx, ax in zip(indices, axes.flatten()):\n",
    "    img_path = Path(dataset_path) / test_generator.filenames[idx]\n",
    "    img = load_img(img_path, target_size=IMG_SIZE)\n",
    "    \n",
    "    true_label = class_names[y_true[idx]]\n",
    "    pred_label = class_names[y_pred[idx]]\n",
    "    confidence = y_pred_proba[idx][0] if y_pred[idx] == 1 else 1 - y_pred_proba[idx][0]\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    color = 'green' if true_label == pred_label else 'red'\n",
    "    title = f'True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.2%}'\n",
    "    ax.set_title(title, fontsize=10, color=color, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55413764",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=3, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier (AUC = 0.5)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.legend(loc=\"lower right\", fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nROC AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5985200",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_curve, recall_curve, _ = precision_recall_curve(y_true, y_pred_proba)\n",
    "avg_precision = average_precision_score(y_true, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(recall_curve, precision_curve, color='blue', lw=3, label=f'PR Curve (AP = {avg_precision:.4f})')\n",
    "plt.axhline(y=precision, color='red', linestyle='--', lw=2, label=f'Current Precision = {precision:.4f}')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall', fontsize=12)\n",
    "plt.ylabel('Precision', fontsize=12)\n",
    "plt.title('Precision-Recall Curve', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.legend(loc=\"lower left\", fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAverage Precision Score: {avg_precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8339d975",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "axes[0].hist(y_pred_proba[y_true == 0], bins=30, alpha=0.7, label='Pen (Class 0)', color='blue', edgecolor='black')\n",
    "axes[0].hist(y_pred_proba[y_true == 1], bins=30, alpha=0.7, label='Pencil (Class 1)', color='orange', edgecolor='black')\n",
    "axes[0].axvline(x=0.5, color='red', linestyle='--', linewidth=2, label='Decision Threshold')\n",
    "axes[0].set_xlabel('Predicted Probability', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Distribution of Prediction Probabilities by Class', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "confidence_pen = y_pred_proba[y_true == 0].flatten()\n",
    "confidence_pencil = y_pred_proba[y_true == 1].flatten()\n",
    "\n",
    "box_data = [1 - confidence_pen, confidence_pencil]\n",
    "box_plot = axes[1].boxplot(box_data, labels=class_names, patch_artist=True,\n",
    "                            showmeans=True, meanline=True)\n",
    "\n",
    "colors = ['lightblue', 'lightcoral']\n",
    "for patch, color in zip(box_plot['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "axes[1].set_ylabel('Confidence Score', fontsize=12)\n",
    "axes[1].set_title('Confidence Score Distribution by True Class', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMean confidence for Pen predictions: {np.mean(1 - confidence_pen):.4f}\")\n",
    "print(f\"Mean confidence for Pencil predictions: {np.mean(confidence_pencil):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c9d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive summary visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.axis('off')\n",
    "\n",
    "summary_text = f\"\"\"\n",
    "╔════════════════════════════════════════════════════════════════════════╗\n",
    "║                    BINARY CLASSIFICATION RESULTS SUMMARY                    ║\n",
    "╠════════════════════════════════════════════════════════════════════════╣\n",
    "║                                                                              ║\n",
    "║  Dataset Information:                                                        ║\n",
    "║  ├─ Total Training Samples: {train_generator.samples:<40}  ║\n",
    "║  ├─ Total Validation Samples: {validation_generator.samples:<38}  ║\n",
    "║  └─ Total Test Samples: {test_generator.samples:<44}  ║\n",
    "║                                                                              ║\n",
    "║  Model Architecture:                                                         ║\n",
    "║  ├─ Base Model: MobileNetV2 (Transfer Learning)                             ║\n",
    "║  ├─ Input Size: 224x224x3                                                   ║\n",
    "║  └─ Output: Binary Classification (Pen vs Pencil)                           ║\n",
    "║                                                                              ║\n",
    "║  Performance Metrics:                                                        ║\n",
    "║  ├─ Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)                                      ║\n",
    "║  ├─ Test Loss: {test_loss:.4f}                                                   ║\n",
    "║  ├─ Precision: {precision:.4f}                                                   ║\n",
    "║  ├─ Recall: {recall:.4f}                                                      ║\n",
    "║  ├─ F1-Score: {f1:.4f}                                                      ║\n",
    "║  ├─ ROC AUC: {roc_auc:.4f}                                                    ║\n",
    "║  └─ Average Precision: {avg_precision:.4f}                                        ║\n",
    "║                                                                              ║\n",
    "║  Confusion Matrix:                                                           ║\n",
    "║  ├─ True Negatives (Pen → Pen): {cm[0][0]:<35}  ║\n",
    "║  ├─ False Positives (Pen → Pencil): {cm[0][1]:<32}  ║\n",
    "║  ├─ False Negatives (Pencil → Pen): {cm[1][0]:<32}  ║\n",
    "║  └─ True Positives (Pencil → Pencil): {cm[1][1]:<30}  ║\n",
    "║                                                                              ║\n",
    "╚════════════════════════════════════════════════════════════════════════╝\n",
    "\"\"\"\n",
    "\n",
    "ax.text(0.5, 0.5, summary_text, \n",
    "        fontsize=11, \n",
    "        family='monospace',\n",
    "        verticalalignment='center',\n",
    "        horizontalalignment='center',\n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "\n",
    "plt.title('Model Evaluation Summary', fontsize=18, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Notebook execution completed successfully!\")\n",
    "print(\"✓ Model trained using transfer learning with MobileNetV2\")\n",
    "print(\"✓ All visualizations and metrics generated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "binary-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
